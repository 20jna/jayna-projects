---
title: "Homework 4"
author: "Jay Na"
date: "Due by 2:20 pm, Fri. 2/15"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
```


Push your knitted homework assignment (.Rmd and .md files) to GitHub by the given deadline.

Also let me know: 

**Who you worked with:**

Dylan Rye

### Problem 1

The vector called `words` in `stringr` contains a corpus of 980 words used in text analysis.  Use regular expressions with `stringr` to find the words that satisfy the following descriptions: 

```{r}
library(stringr)
```
- begin with `b`
```{r}
str_subset(words, pattern = "^b")
```
- contain `q`, `x`, or `z`
```{r}
str_subset(words, pattern = "[qxz]")
```
- contain `th` or `ch`
```{r}
str_subset(words, pattern = "(t|c)h")
```
- end with `g` but not `ng`
```{r}
str_subset(words, pattern = "[^n]g$")
```
- are 10 letters long
```{r}
str_subset(words, pattern = "^..........$")
```

```diff
+ can also try "^.{10}$"
```

- have 3 or more vowels in a row
```{r}
str_subset(words, pattern = "[aeiouy]{3,}")
```
- start and end with the same letter
```{r}
str_subset(words, pattern = "^(.)((.*\\1$)|\\1?$)")
```

### Problem 2

Revisit the `words` vector. What word, or words, in this vector has the highest number of vowels? What word has the highest proportion of vowels?

```{r}
vowel_count <-str_count(words, pattern = "[aeiouy]")
words[which(vowel_count == max(vowel_count))]
```

```{r}
vowel_prop <- str_count(words, "[aeiouy]") / str_length(words)
words[which(vowel_prop == max(vowel_prop))]
```

### Problem 3

(Combining exercise 15.6 and 15.7)

Project Gutenberg contains the full text of *The Complete Works of William Shakespeare*. (http://www.gutenberg.org/files/100/100-0.txt)


**(a)** Use the `read_lines()` in **readr** to import the text data.
```{r}
library(readr)
shakespeare <- read_lines("http://www.gutenberg.org/files/100/100-0.txt")
```

**(b)** Use regular expressions to determine the number of speaking lines in *The Complete Works of William Shakespeare*.  Speaking lines in Shakespeare’s plays are identified by a line that starts with two spaces, then a string of capital letters and spaces (the character’s name) followed by a period. Here, we care only about how many times a character speaks—not what they say or for how long they speak.
```{r}
speaking_lines <- grep("^[A-Z]{2,}\\.", shakespeare, value = TRUE)
length(speaking_lines)
```
There are 9260 speaking lines.

```diff
+ these words need to start with two spaces
```

**(c)** Make a bar chart displaying the top 100 characters with the greatest number of lines. *Hint:* you may want to use either the `str extract()`.
```{r}
library(tidyverse)

characters <- tibble(words = unlist(str_extract(speaking_lines, boundary("word")))) %>%
    mutate(words = str_to_lower(words)) %>%
    count(words, sort = TRUE) %>%
    head(100)

characters$lines <- characters$n 
characters %>%
  select(1,3)

ggplot(data = characters, aes(x = reorder(words, lines), y = lines)) +
  geom_bar(stat="identity") + labs(title = "Top 100 Characters by # of Speaking Lines", x = "Name of Characters", y = "Number of Lines")  + coord_flip()
```

### Problem 4

Scrape the table of data found at https://en.wikipedia.org/wiki/List_of_United_States_cities_by_crime_rate and create a plot showing violent crime rate (total violent crime) vs. property crime rate (total property crime).  Identify outlier cities by using a plotting command such as:

```{r, eval = FALSE}
library(tidyverse)

ggplot(crimes, aes(x = VCrate, y = PCrate, label = City)) +
    geom_point() +
    geom_text(data=subset(crimes4, VCrate > 1500 | PCrate > 6500), 
              check_overlap = TRUE, size = 2.5, nudge_y = 200)
```

Hints:

- after reading in the table using `html_table()`, create a data frame with just the columns you want using column numbers.  Otherwise, R gets confused since it appears as if several columns all have the same column name.
- then, turn `crimes` into a tibble with `as.tibble(crimes3)` and do necessary tidying: get rid of unneeded rows, parse columns into proper format, etc.

Alternatives to `geom_text()`:

If you want to try something new, check out the **ggrepel** package to label the outliers.

```{r}
library(rvest)
library(ggrepel)

crimerate <- read_html("https://en.wikipedia.org/wiki/List_of_United_States_cities_by_crime_rate") %>%
  html_nodes("table")

crimes <- html_table(crimerate[[1]], fill = TRUE)

names(crimes)[4]<-paste("violence")
names(crimes)[10]<-paste("property")
names(crimes)[5]<-paste("useless1")
names(crimes)[6]<-paste("useless2")
names(crimes)[7]<-paste("useless3")
names(crimes)[8]<-paste("useless4")
names(crimes)[9]<-paste("useless5")
names(crimes)[11]<-paste("useless6")
names(crimes)[12]<-paste("useless7")
names(crimes)[13]<-paste("useless8")

crimes2<- crimes %>%
  select(2,4,10) %>%
  as_tibble()
crimes2 <- crimes2[-1,]

ggplot(crimes2, aes(x = as.numeric(violence), y = as.numeric(property), label = City)) +
    geom_point() + geom_text_repel(data=subset(crimes2, violence > 1500 | property > 1500), size = 2) +
  labs(title = "Crime Rate of US Cities", x = "Violent Crime Rate", y = "Property Crime Rate")
```

```diff
+ you only need to identify the outliers
```

### Problem 5

Scrape the data from IMDB's top grossing films released in 2018 at https://www.imdb.com/search/title?year=2018&title_type=feature&sort=boxoffice_gross_us,desc.  Create a tibble that contains the title, gross, imdbscore, and metascore for the top 50 films.  Then generate a scatterplot of one of the ratings vs. gross, labeling outliers as in Problem 4 with the title of the movie.

```{r}
title <- read_html("https://www.imdb.com/search/title?year=2018&title_type=feature&sort=boxoffice_gross_us,desc") %>%
html_nodes(".lister-item-header") %>%
html_text() %>%
str_match("\n.*\n.*\\(2018\\)") %>%
str_match("\n.*\n") %>%
str_sub(., 6, -2) %>%
as.tibble()

gross <- read_html("https://www.imdb.com/search/title?year=2018&title_type=feature&sort=boxoffice_gross_us,desc") %>%
html_nodes(".sort-num_votes-visible") %>%
html_text() %>%
str_match(., "\\$.*M") %>%
str_sub(., 2, -2) %>%
as.numeric() %>%
as.tibble()

imdbscore <- read_html("https://www.imdb.com/search/title?year=2018&title_type=feature&sort=boxoffice_gross_us,desc") %>%
html_nodes(".ratings-imdb-rating") %>%
html_text() %>%
str_match(., "\\d\\.\\d") %>%
as.numeric() %>%
as.tibble()

metascore <- read_html("https://www.imdb.com/search/title?year=2018&title_type=feature&sort=boxoffice_gross_us,desc") %>%
html_nodes(".ratings-metascore") %>%
html_text() %>%
str_match(., "\\d{2}") %>%
as.numeric() %>%
as.tibble() %>%
add_row(., value = NA, .after = 35)

top50 <- bind_cols(title, gross, imdbscore, metascore)
colnames(top50) <- c("title", "gross", "imdbscore", "metascore")

ggplot(data = top50, mapping = aes(x = metascore, y = gross, label = title)) + 
  geom_point() + 
  geom_text_repel(data = subset(top50, gross > 400 | metascore > 80), check_overlap = TRUE, size = 3, nudge_y = 50) + 
  labs(y = "Gross Earnings (in Millions of Dollars)", x= "Metascore", title = "Top Grossing Movies in the US", subtitle = "2018")
```
